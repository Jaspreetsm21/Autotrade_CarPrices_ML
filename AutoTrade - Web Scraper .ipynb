{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Auto trade website to extract relevant information about cars using BeautifulSoup Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto trade only allows to scraper top 1000 listing per search. To extract large amount of data, I created a list of postcode around the UK and used for loop to scraper car data around postcodes and pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I decided to pick 10 postcodes around the UK to extract large amount of data as 1000 listing per Search and each page has roughly 10 car listings\n",
    "\n",
    "2. I'm extracting information like car title, prices, mileage, engine size ,gearbox and etc.\n",
    "\n",
    "3. I have also created a empty list and appending the extract data into that list\n",
    "\n",
    "4. Converting list to DataFrame\n",
    "\n",
    "5. Exporting data into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create the following postcodes\n",
    "postcode = ['BH11AR','SL14DX','SY231AB','TR196PJ','BN207AE','BS247EY','NR293PS','PE251FD','LL536ED','HS29DX']\n",
    "\n",
    "\n",
    "for page in range(0, 100):  #each pages has 10 listing, so the range is set up for 100 (1000 listing per search)\n",
    "    for code in postcode:   #each postcode \n",
    "        \n",
    "        #url for the web scraper \n",
    "        \n",
    "        req_url = f\"https://www.autotrader.co.uk/car-search?sort=distance&\" \\\n",
    "                f\"postcode={code}&radius=200&onesearchad=Used&onesearchad=Nearly%20New&\" \\\n",
    "                f\"onesearchad=New&page={page}\"\n",
    "        \n",
    "        req = urlopen(req_url)\n",
    "        #print(req_url)\n",
    "        page_html = req.read()\n",
    "        req.close()\n",
    "        page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # BeautifulSoup.findAll is deprecated use find_all instead\n",
    "        listings = page_soup.find_all(\"li\", {\"class\": \"search-page__result\"})\n",
    "        for listing in listings:\n",
    "            information_container = listing.find(\"div\", {\"class\": \"information-container\"})\n",
    "            title_container = information_container.find(\"a\", {\n",
    "                \"class\": \"js-click-handler listing-fpa-link tracking-standard-link\"})\n",
    "            title = title_container.text.replace('\\n',' ')\n",
    "            price = listing.find(\"div\", {\"class\": \"vehicle-price\"}).text\n",
    "            \n",
    "\n",
    "            information_container = listing.find(\"div\", {\"class\": \"information-container\"})\n",
    "            title_container = information_container.find(\"a\", {\n",
    "                \"class\": \"js-click-handler listing-fpa-link tracking-standard-link\"})\n",
    "            title = title_container.text.replace('\\n',' ')\n",
    "            price = listing.find(\"div\", {\"class\": \"vehicle-price\"}).text\n",
    "            #print(title,price)\n",
    "            car_title.append(title)\n",
    "            car_price.append(price)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Vehcile Information\n",
    "            Reg_Year = listing.find(\"ul\", {\"class\": \"listing-key-specs\"}).text.split()\n",
    "            print(Reg_Year)\n",
    "            try:\n",
    "                Year_Register = Reg_Year[0]\n",
    "                Type_Door = Reg_Year[3]\n",
    "                milleage  = Reg_Year[4]\n",
    "                engine_size   = Reg_Year[6]\n",
    "                Horse_PW   = Reg_Year[7]\n",
    "                Type_Vehicle   = Reg_Year[8]\n",
    "                Filling_in   = Reg_Year[9]\n",
    "            except:\n",
    "                Year_Register = None\n",
    "                Type_Door = None\n",
    "                milleage  = None\n",
    "                engine_size   = None\n",
    "                Horse_PW   = None\n",
    "                Type_Vehicle   =None\n",
    "                Filling_in   = None\n",
    "            \n",
    "            #print(title,price,Year_Register,Type_Door,milleage,engine_size,Horse_PW,Type_Vehicle,Filling_in)\n",
    "            Car_Year.append(Year_Register)\n",
    "            Car_Type_Door.append(Type_Door)\n",
    "            Car_Mileage.append(milleage)\n",
    "            Car_engine_size.append(engine_size)\n",
    "            Car_Horse_PW.append(Horse_PW)\n",
    "            Car_Type_Vehicle.append(Type_Vehicle)\n",
    "            Car_Filling_in.append(Filling_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({ 'Car_Title':car_title,\n",
    "  'Car_Price':car_price,\n",
    "  'Car_Year': Car_Year,\n",
    "  'Car_Type_Door':Car_Type_Door,\n",
    "  'Car_Mileage':Car_Mileage,\n",
    "  'Car_engine_size':Car_engine_size,\n",
    "  'Car_Horse_PW':Car_Horse_PW,\n",
    "  'Car_Type_Vehicle':Car_Type_Vehicle,\n",
    "  'Car_Filling_in':Car_Filling_in\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scraped from each of the postcode can overlap each other, so I'm going to drop any duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('auto_scraper.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
